
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Insight\_demo}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \paragraph{Let's start by calling in all our libraries. I will also
initialize a set.seed to make sure that my results are as reproducible
as
possible.}\label{lets-start-by-calling-in-all-our-libraries.-i-will-also-initialize-a-set.seed-to-make-sure-that-my-results-are-as-reproducible-as-possible.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kp}{setwd}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{/Users/balaji/Documents/Balaji/Coursera/UCI HAR Dataset\PYZsq{}}\PY{p}{)}
        \PY{k+kn}{library}\PY{p}{(}glmnet\PY{p}{)}
        \PY{k+kn}{library}\PY{p}{(}caret\PY{p}{)}
        \PY{k+kn}{library}\PY{p}{(}dplyr\PY{p}{)}
        \PY{k+kp}{set.seed}\PY{p}{(}\PY{l+m}{0226}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Loading required package: Matrix
Loading required package: foreach
Loaded glmnet 2.0-13

Loading required package: lattice
Loading required package: ggplot2

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union


    \end{Verbatim}

    \paragraph{Let's start by reading in the file with predictors for our
training
dataset}\label{lets-start-by-reading-in-the-file-with-predictors-for-our-training-dataset}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} x.train \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{train/X\PYZus{}train.txt\PYZsq{}}\PY{p}{,} header\PY{o}{=}\PY{n+nb+bp}{F}\PY{p}{)}
        
        \PY{k+kp}{print}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The predictor training dataset contains\PYZdq{}}\PY{p}{,} \PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{rownames}\PY{p}{(}x.train\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{observations for\PYZdq{}}\PY{p}{,} 
                    \PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{colnames}\PY{p}{(}x.train\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{variables\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1] "This training dataset contains 7352 observations for 561 variables"

    \end{Verbatim}

    \paragraph{Are there any missing values in the training predictor
dataset? Let's also take a quick look at the
dataset.}\label{are-there-any-missing-values-in-the-training-predictor-dataset-lets-also-take-a-quick-look-at-the-dataset.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k+kp}{print}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The number of missing values in this dataset is:\PYZdq{}}\PY{p}{,}\PY{k+kp}{sum}\PY{p}{(}\PY{k+kp}{is.na}\PY{p}{(}x.train\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{k+kp}{print}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Let\PYZsq{}s take a look at the first 5 rows and columns of the training dataset \PYZbs{}n\PYZdq{}}\PY{p}{)}
        x.train\PY{p}{[}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{5}\PY{p}{,}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{5}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1] "The number of missing values in this dataset is: 0"
[1] "Let's take a look at the first 5 rows and columns of the training dataset \textbackslash{}n"

    \end{Verbatim}

    \begin{tabular}{r|lllll}
 V1 & V2 & V3 & V4 & V5\\
\hline
	 0.2885845   & -0.02029417 & -0.1329051  & -0.9952786  & -0.9831106 \\
	 0.2784188   & -0.01641057 & -0.1235202  & -0.9982453  & -0.9753002 \\
	 0.2796531   & -0.01946716 & -0.1134617  & -0.9953796  & -0.9671870 \\
	 0.2791739   & -0.02620065 & -0.1232826  & -0.9960915  & -0.9834027 \\
	 0.2766288   & -0.01656965 & -0.1153619  & -0.9981386  & -0.9808173 \\
\end{tabular}


    
    \paragraph{We see that the predictors are missing column names. Luckily,
these are available in the features.txt file. Let's take a quick look at
them}\label{we-see-that-the-predictors-are-missing-column-names.-luckily-these-are-available-in-the-features.txt-file.-lets-take-a-quick-look-at-them}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} These are the names for each of the predictor variables}
        feat\PYZus{}labels \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{features.txt\PYZsq{}}\PY{p}{,} row.names \PY{o}{=} \PY{l+m}{1}\PY{p}{,} stringsAsFactors \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}
        \PY{k+kp}{head}\PY{p}{(}feat\PYZus{}labels\PY{p}{)}
\end{Verbatim}


    \begin{tabular}{r|l}
 V2\\
\hline
	 tBodyAcc-mean()-X\\
	 tBodyAcc-mean()-Y\\
	 tBodyAcc-mean()-Z\\
	 tBodyAcc-std()-X \\
	 tBodyAcc-std()-Y \\
	 tBodyAcc-std()-Z \\
\end{tabular}


    
    \paragraph{Let's check to see if there are any missing values in this
vector. Then we'll check to ensure that the names are all unique.
Finally, we'll use 'make.names' to remove the formatting from the
names.}\label{lets-check-to-see-if-there-are-any-missing-values-in-this-vector.-then-well-check-to-ensure-that-the-names-are-all-unique.-finally-well-use-make.names-to-remove-the-formatting-from-the-names.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Any missing values in this vector}
        \PY{k+kp}{print}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The number of missing values in the labels vector is\PYZdq{}}\PY{p}{,} \PY{k+kp}{sum}\PY{p}{(}\PY{k+kp}{is.na}\PY{p}{(}feat\PYZus{}labels\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{} How many values are unique}
        \PY{k+kp}{print}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The number of unique column names are:\PYZdq{}}\PY{p}{,}\PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{unique}\PY{p}{(}feat\PYZus{}labels\PY{o}{\PYZdl{}}V2\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1] "The number of missing values in the labels vector is 0"
[1] "The number of unique column names are: 477"

    \end{Verbatim}

    \paragraph{Looks like only 477/561 values are unique. We can deal with
that in the make.names call. We will then assign the unique column names
to the training
predictors}\label{looks-like-only-477561-values-are-unique.-we-can-deal-with-that-in-the-make.names-call.-we-will-then-assign-the-unique-column-names-to-the-training-predictors}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Make the feature labels unique by applying the make.names function}
        feat\PYZus{}labels\PY{o}{\PYZdl{}}V2 \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{make.names}\PY{p}{(}feat\PYZus{}labels\PY{o}{\PYZdl{}}V2\PY{p}{,} unique \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}\PYZsh{} Assign the unique names we created as column names for X.train}
        \PY{k+kp}{colnames}\PY{p}{(}x.train\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} feat\PYZus{}labels\PY{o}{\PYZdl{}}V2
\end{Verbatim}


    \paragraph{Let's now turn our attention to the target variable. Let's
read it in, check its dimensions, take a look at its contents, and also
check for missing
values.}\label{lets-now-turn-our-attention-to-the-target-variable.-lets-read-it-in-check-its-dimensions-take-a-look-at-its-contents-and-also-check-for-missing-values.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Read\PYZhy{}in the target value for the training dataset}
        Y.train \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{train/y\PYZus{}train.txt\PYZsq{}}\PY{p}{,} header\PY{o}{=}\PY{n+nb+bp}{F}\PY{p}{,} col.names \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{target\PYZsq{}}\PY{p}{)}
        \PY{k+kp}{print}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The target values for the training dataset contains\PYZdq{}}\PY{p}{,}\PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{rownames}\PY{p}{(}Y.train\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{observations for\PYZdq{}}\PY{p}{,}
                    \PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{colnames}\PY{p}{(}Y.train\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{ variables\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{and contains \PYZdq{}}\PY{p}{,} \PY{k+kp}{length}\PY{p}{(}\PY{k+kp}{levels}\PY{p}{(}\PY{k+kp}{as.factor}\PY{p}{(}Y.train\PY{o}{\PYZdl{}}target\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{ levels\PYZdq{}}\PY{p}{)}\PY{p}{)}
        
        \PY{k+kp}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The levels of the target values are: \PYZbs{}n\PYZdq{}}\PY{p}{,}\PY{k+kp}{levels}\PY{p}{(}\PY{k+kp}{as.factor}\PY{p}{(}Y.train\PY{o}{\PYZdl{}}target\PY{p}{)}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{} Any Missing values in the dataset?}
        \PY{k+kp}{cat}\PY{p}{(}\PY{k+kp}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nThe number of missing values in this dataset is: \PYZdq{}}\PY{p}{,}\PY{p}{(}\PY{k+kp}{sum}\PY{p}{(}\PY{k+kp}{is.na}\PY{p}{(}Y.train\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1] "The target values for the training dataset contains 7352 observations for 1  variables and contains  6  levels"
The levels of the target values are: 
 1 2 3 4 5 6
The number of missing values in this dataset is:  0
    \end{Verbatim}

    \paragraph{We can see that there are 6 levels. What do these numbers
stand for? - The answer lies in the 'activity\_labels.txt'. Let's take a
look at that file and add those values to the target variable
df}\label{we-can-see-that-there-are-6-levels.-what-do-these-numbers-stand-for---the-answer-lies-in-the-activity_labels.txt.-lets-take-a-look-at-that-file-and-add-those-values-to-the-target-variable-df}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Read in the labels for each activity}
        activity\PYZus{}labels \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{activity\PYZus{}labels.txt\PYZsq{}}\PY{p}{,}header \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{,} row.names \PY{o}{=} \PY{l+m}{1}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{} Add in the Activtiy labels using the mutate function in dplyr}
        Y.train \PY{o}{\PYZlt{}\PYZhy{}} Y.train \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} as\PYZus{}tibble\PY{p}{(}\PY{p}{)} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} mutate\PY{p}{(}target\PY{p}{,} Activity \PY{o}{=} \PY{k+kp}{ifelse}\PY{p}{(} target \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+m}{6}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Laying\PYZdq{}}\PY{p}{,}\PY{k+kp}{ifelse}\PY{p}{(} target \PY{o}{==} \PY{l+m}{5}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Standing\PYZdq{}}\PY{p}{,} 
                                                  \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{4}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Sitting\PYZdq{}}\PY{p}{,} \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{3}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZus{}Downstairs\PYZdq{}}\PY{p}{,}
                                                  \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{2}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZus{}Upstairs\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} \PY{k+kp}{as.data.frame}
        \PY{k+kp}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Now, our target variable df looks like this: \PYZbs{}n\PYZdq{}}\PY{p}{)}
        \PY{k+kp}{head}\PY{p}{(}Y.train\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        Error in eval(lhs, parent, parent): object 'Y.train' not found
    Traceback:


        1. Y.train \%>\% as\_tibble() \%>\% mutate(target, Activity = ifelse(target \%in\% 
     .     6, "Laying", ifelse(target == 5, "Standing", ifelse(target == 
     .     4, "Sitting", ifelse(target == 3, "Walking\_Downstairs", ifelse(target == 
     .     2, "Walking\_Upstairs", "Walking")))))) \%>\% as.data.frame

        2. eval(lhs, parent, parent)

        3. eval(lhs, parent, parent)

    \end{Verbatim}

    \paragraph{In a typical real-world situation, we may not have a test
dataset to validate our model. This will require partioning our training
dataset. Here, I will partition the training dataset (80/20) to ensure
that its performance does not deviate significantly from the training
dataset to the test dataset. We will then subset our training dataset
accordingly.}\label{in-a-typical-real-world-situation-we-may-not-have-a-test-dataset-to-validate-our-model.-this-will-require-partioning-our-training-dataset.-here-i-will-partition-the-training-dataset-8020-to-ensure-that-its-performance-does-not-deviate-significantly-from-the-training-dataset-to-the-test-dataset.-we-will-then-subset-our-training-dataset-accordingly.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Create partitions of the dataset for training/calibration}
         x.train.ind \PY{o}{\PYZlt{}\PYZhy{}} createDataPartition\PY{p}{(}Y.train\PY{o}{\PYZdl{}}Activity\PY{p}{,} times \PY{o}{=} \PY{l+m}{1}\PY{p}{,} p\PY{o}{=}\PY{l+m}{0.8}\PY{p}{,} \PY{k+kt}{list} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} subset the training dataset (and the labels) [The 80\PYZpc{} of training set]}
         train \PY{o}{\PYZlt{}\PYZhy{}} x.train\PY{p}{[}x.train.ind\PY{p}{,}\PY{p}{]}
         train\PYZus{}labels \PY{o}{\PYZlt{}\PYZhy{}} Y.train\PY{p}{[}x.train.ind\PY{p}{,}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} subset the training dataset (and the labels) [The 20\PYZpc{} used for calibrating our model]}
         rem\PYZus{}train \PY{o}{\PYZlt{}\PYZhy{}} x.train\PY{p}{[}\PY{o}{\PYZhy{}}x.train.ind\PY{p}{,}\PY{p}{]}
         rem\PYZus{}train\PYZus{}labels \PY{o}{\PYZlt{}\PYZhy{}} Y.train\PY{p}{[}\PY{o}{\PYZhy{}}x.train.ind\PY{p}{,}\PY{p}{]}
\end{Verbatim}


    \paragraph{Now, we're ready to start the business end of this exercise.
We're ready to build a model using our training predictor set. We will
be doing this using the glmnet package. We will also generate a plot to
assess the output from
glmnet}\label{now-were-ready-to-start-the-business-end-of-this-exercise.-were-ready-to-build-a-model-using-our-training-predictor-set.-we-will-be-doing-this-using-the-glmnet-package.-we-will-also-generate-a-plot-to-assess-the-output-from-glmnet}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Since we have a ton of features to predict from, we need to build models and select the features that best predict }
         \PY{c+c1}{\PYZsh{}\PYZsh{} the target variable}
         \PY{c+c1}{\PYZsh{}\PYZsh{} The glmnet function builds a number of models}
         testglm \PY{o}{\PYZlt{}\PYZhy{}} glmnet\PY{p}{(}\PY{k+kp}{as.matrix}\PY{p}{(}train\PY{p}{)}\PY{p}{,} train\PYZus{}labels\PY{o}{\PYZdl{}}Activity\PY{p}{,} family \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{multinomial\PYZsq{}}\PY{p}{,} type.multinomial \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{grouped\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} Generate a plot to assess the results from model building}
         plot\PY{p}{(}testglm\PY{p}{,} xvar \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{lambda\PYZdq{}}\PY{p}{,} label \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{,} type.coef \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{2norm\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Warning message:
“from glmnet Fortran code (error code -74); Convergence for 74th lambda value not reached after maxit=100000 iterations; solutions for larger lambdas returned”
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_19_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{The plot above tells us that as lambda decreases (right to
left), the model's reliance on certain feature increases - a sign of
overfitting to the training dataset. log lambda vs fraction deviance is
another good way to assess model performance across the range of
lambda.}\label{the-plot-above-tells-us-that-as-lambda-decreases-right-to-left-the-models-reliance-on-certain-feature-increases---a-sign-of-overfitting-to-the-training-dataset.-log-lambda-vs-fraction-deviance-is-another-good-way-to-assess-model-performance-across-the-range-of-lambda.}

Now that glmnet has generated multiple models of the training dataset
that best explain our target variable. Let's perform a 10-fold
cross-validation to select the best lambda that explains our model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Perform Cross\PYZhy{}validation to find the features with the lowest error values}
         \PY{k+kn}{require}\PY{p}{(}doMC\PY{p}{)}
         registerDoMC\PY{p}{(}cores \PY{o}{=} \PY{l+m}{8}\PY{p}{)}
         glm.fit \PY{o}{\PYZlt{}\PYZhy{}} cv.glmnet\PY{p}{(}\PY{k+kp}{as.matrix}\PY{p}{(}train\PY{p}{)}\PY{p}{,} train\PYZus{}labels\PY{o}{\PYZdl{}}Activity\PY{p}{,} family \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{multinomial\PYZsq{}}\PY{p}{,}
                              type.measure \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{class\PYZsq{}}\PY{p}{,} nfolds \PY{o}{=} \PY{l+m}{10}\PY{p}{,} parallel \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} Let\PYZsq{}s visualize the results of our cross\PYZhy{}validation }
         plot\PY{p}{(}glm.fit\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Loading required package: doMC
Loading required package: iterators
Loading required package: parallel

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{A quick look at the plot (from left to right) shows the
lowest lambda and one standard error of the lambda. We will use
one-standard error of the lambda to predict the 20\% of the training
dataset that we had sliced off
earlier.}\label{a-quick-look-at-the-plot-from-left-to-right-shows-the-lowest-lambda-and-one-standard-error-of-the-lambda.-we-will-use-one-standard-error-of-the-lambda-to-predict-the-20-of-the-training-dataset-that-we-had-sliced-off-earlier.}

\begin{itemize}
\tightlist
\item
  The reason we use one standard error of the lambda is because
  lambda.min tends to 'shift' every time this making the model rigid. On
  the other hand, the lambda.1se preserves the ability of the model to
  remain flexible.
\item
  We will initiate the prediction call with 'type = class', so we get
  factor predictions (laying, standing, etc..) We will then compare the
  predicted findings to the target values
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Let\PYZsq{}s use the model we just created to make predictions for the 20\PYZpc{} we set aside for calibrating our model}
         rem.pred \PY{o}{\PYZlt{}\PYZhy{}} predict\PY{p}{(}glm.fit\PY{p}{,} s \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{lambda.1se\PYZdq{}}\PY{p}{,} newx \PY{o}{=} \PY{k+kp}{as.matrix}\PY{p}{(}rem\PYZus{}train\PY{p}{)}\PY{p}{,} type \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{class\PYZsq{}}\PY{p}{)}
         confusionMatrix\PY{p}{(}rem.pred\PY{p}{,} rem\PYZus{}train\PYZus{}labels\PY{o}{\PYZdl{}}Activity\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
Confusion Matrix and Statistics

                    Reference
Prediction           Laying Sitting Standing Walking Walking_Downstairs
  Laying                281       0        0       0                  0
  Sitting                 0     252        8       0                  0
  Standing                0       4      265       0                  0
  Walking                 0       1        1     245                  0
  Walking_Downstairs      0       0        0       0                196
  Walking_Upstairs        0       0        0       0                  1
                    Reference
Prediction           Walking_Upstairs
  Laying                            0
  Sitting                           0
  Standing                          0
  Walking                           0
  Walking_Downstairs                0
  Walking_Upstairs                214

Overall Statistics
                                          
               Accuracy : 0.9898          
                 95% CI : (0.9832, 0.9943)
    No Information Rate : 0.1914          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9877          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: Laying Class: Sitting Class: Standing
Sensitivity                 1.0000         0.9805          0.9672
Specificity                 1.0000         0.9934          0.9966
Pos Pred Value              1.0000         0.9692          0.9851
Neg Pred Value              1.0000         0.9959          0.9925
Prevalence                  0.1914         0.1751          0.1866
Detection Rate              0.1914         0.1717          0.1805
Detection Prevalence        0.1914         0.1771          0.1832
Balanced Accuracy           1.0000         0.9870          0.9819
                     Class: Walking Class: Walking_Downstairs
Sensitivity                  1.0000                    0.9949
Specificity                  0.9984                    1.0000
Pos Pred Value               0.9919                    1.0000
Neg Pred Value               1.0000                    0.9992
Prevalence                   0.1669                    0.1342
Detection Rate               0.1669                    0.1335
Detection Prevalence         0.1683                    0.1335
Balanced Accuracy            0.9992                    0.9975
                     Class: Walking_Upstairs
Sensitivity                           1.0000
Specificity                           0.9992
Pos Pred Value                        0.9953
Neg Pred Value                        1.0000
Prevalence                            0.1458
Detection Rate                        0.1458
Detection Prevalence                  0.1465
Balanced Accuracy                     0.9996
    \end{verbatim}

    
    \subsubsection{Finally, we read in the test dataset, add in the activity
labels, make predictions and compare them to the predicted
results.}\label{finally-we-read-in-the-test-dataset-add-in-the-activity-labels-make-predictions-and-compare-them-to-the-predicted-results.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Read in the test x values}
         x.test \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{test/X\PYZus{}test.txt\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} Read in the tesy y values}
         Y.test \PY{o}{\PYZlt{}\PYZhy{}} read.table\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{test/y\PYZus{}test.txt\PYZsq{}}\PY{p}{,} header\PY{o}{=}\PY{n+nb+bp}{F}\PY{p}{,} col.names \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{target\PYZsq{}}\PY{p}{)} 
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} Add in the Activtiy labels using the mutate function in dplyr}
         Y.test \PY{o}{\PYZlt{}\PYZhy{}} Y.test \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} as\PYZus{}tibble\PY{p}{(}\PY{p}{)} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} mutate\PY{p}{(}target\PY{p}{,} Activity \PY{o}{=} \PY{k+kp}{ifelse}\PY{p}{(} target \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+m}{6}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Laying\PYZdq{}}\PY{p}{,}\PY{k+kp}{ifelse}\PY{p}{(} target \PY{o}{==} \PY{l+m}{5}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Standing\PYZdq{}}\PY{p}{,} 
                                                     \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{4}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Sitting\PYZdq{}}\PY{p}{,} \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{3}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZus{}Downstairs\PYZdq{}}\PY{p}{,}
                                                     \PY{k+kp}{ifelse}\PY{p}{(}target \PY{o}{==} \PY{l+m}{2}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZus{}Upstairs\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Walking\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} \PY{k+kp}{as.data.frame}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{} Finally, predict the test values and calculate the accuracy of that prediction}
         test.pred \PY{o}{\PYZlt{}\PYZhy{}} predict\PY{p}{(}glm.fit\PY{p}{,} s\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{lambda.1se\PYZsq{}}\PY{p}{,} newx\PY{o}{=}\PY{k+kp}{as.matrix}\PY{p}{(}x.test\PY{p}{)}\PY{p}{,} type\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{class\PYZsq{}}\PY{p}{)}
         confusionMatrix\PY{p}{(}test.pred\PY{p}{,} Y.test\PY{o}{\PYZdl{}}Activity\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
Confusion Matrix and Statistics

                    Reference
Prediction           Laying Sitting Standing Walking Walking_Downstairs
  Laying                533       0        0       0                  0
  Sitting                 0     432       18       0                  0
  Standing                4      56      513       0                  0
  Walking                 0       0        1     492                  5
  Walking_Downstairs      0       0        0       2                392
  Walking_Upstairs        0       3        0       2                 23
                    Reference
Prediction           Walking_Upstairs
  Laying                            0
  Sitting                           0
  Standing                          0
  Walking                          34
  Walking_Downstairs                4
  Walking_Upstairs                433

Overall Statistics
                                          
               Accuracy : 0.9484          
                 95% CI : (0.9398, 0.9561)
    No Information Rate : 0.1822          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.938           
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: Laying Class: Sitting Class: Standing
Sensitivity                 0.9926         0.8798          0.9643
Specificity                 1.0000         0.9927          0.9752
Pos Pred Value              1.0000         0.9600          0.8953
Neg Pred Value              0.9983         0.9764          0.9920
Prevalence                  0.1822         0.1666          0.1805
Detection Rate              0.1809         0.1466          0.1741
Detection Prevalence        0.1809         0.1527          0.1944
Balanced Accuracy           0.9963         0.9363          0.9697
                     Class: Walking Class: Walking_Downstairs
Sensitivity                  0.9919                    0.9333
Specificity                  0.9837                    0.9976
Pos Pred Value               0.9248                    0.9849
Neg Pred Value               0.9983                    0.9890
Prevalence                   0.1683                    0.1425
Detection Rate               0.1669                    0.1330
Detection Prevalence         0.1805                    0.1351
Balanced Accuracy            0.9878                    0.9655
                     Class: Walking_Upstairs
Sensitivity                           0.9193
Specificity                           0.9887
Pos Pred Value                        0.9393
Neg Pred Value                        0.9847
Prevalence                            0.1598
Detection Rate                        0.1469
Detection Prevalence                  0.1564
Balanced Accuracy                     0.9540
    \end{verbatim}

    

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
